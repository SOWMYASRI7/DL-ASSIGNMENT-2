# -*- coding: utf-8 -*-
"""2-gpt2-ed-coldplay.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qz0minjbjE9bEduUx2U6RsEjkzjIRB5R
"""

!pip install transformers datasets

import os
os.environ["WANDB_DISABLED"] = "true"

import pandas as pd
from datasets import Dataset
from transformers import (
    GPT2Tokenizer,
    GPT2LMHeadModel,
    Trainer,
    TrainingArguments,
    DataCollatorForLanguageModeling,
    pipeline,
)
import torch

from google.colab import files
uploaded = files.upload()  # Upload the EdSheeran_Coldplay_Lyrics.xlsx file

df = pd.read_excel("EdSheeran_Coldplay_Lyrics.xlsx")
df = df.dropna(subset=["LYRICS"])
df = df[df["LYRICS"].apply(lambda x: isinstance(x, str) and len(x.strip()) > 0)]
dataset = Dataset.from_dict({"text": df["LYRICS"].tolist()})

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
tokenizer.pad_token = tokenizer.eos_token

model = GPT2LMHeadModel.from_pretrained("gpt2")

def tokenize(example):
    return tokenizer(example["text"], truncation=True, padding="max_length", max_length=128)

tokenized_dataset = dataset.map(tokenize, batched=True)

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

training_args = TrainingArguments(
    output_dir="./gpt2-ed-coldplay",
    overwrite_output_dir=True,
    per_device_train_batch_size=2,
    num_train_epochs=3,
    logging_steps=50,
    save_steps=200,
    save_total_limit=1,
    prediction_loss_only=True,
    fp16=torch.cuda.is_available()
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator,
)

trainer.train()

trainer.save_model("./gpt2-ed-coldplay")
tokenizer.save_pretrained("./gpt2-ed-coldplay")

generator = pipeline('text-generation', model="./gpt2-ed-coldplay", tokenizer=tokenizer)

prompts = [
    "I'm in love with the shape",
    "Look at the stars, look how",
]

for prompt in prompts:
    print(f"\nPrompt: {prompt}")
    output = generator(prompt, max_length=100, num_return_sequences=1)[0]["generated_text"]
    print(f"Generated Lyrics:\n{output}")